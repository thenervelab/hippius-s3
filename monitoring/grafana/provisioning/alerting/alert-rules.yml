apiVersion: 1

groups:
  - orgId: 1
    name: hippius-s3-critical
    folder: Hippius S3 Alerts
    interval: 1m
    rules:
      - uid: redis-memory-exhaustion
        title: Redis Memory Exhaustion
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: PBFA97CFB590B2093
            model:
              expr: '(redis_memory_used_bytes / redis_memory_max_bytes) * 100'
              refId: A
          - refId: B
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: reduce
              expression: A
              reducer: last
              refId: B
          - refId: C
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: threshold
              expression: B
              conditions:
                - evaluator:
                    params:
                      - 90
                    type: gt
                  type: query
              refId: C
        noDataState: OK
        execErrState: Error
        for: 3m
        annotations:
          description: 'Redis memory usage is {{ if $values.B }}{{ printf "%.2f" $values.B.Value }}{{ else }}N/A{{ end }}% (threshold: 90%)'
          summary: Redis memory usage critically high
        labels:
          severity: critical

      - uid: queue-backup-critical
        title: Queue Backup Critical
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: PBFA97CFB590B2093
            model:
              expr: 'max(hippius_queue_length{queue_name=~"upload_requests|substrate_requests"})'
              refId: A
          - refId: B
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: reduce
              expression: A
              reducer: last
              refId: B
          - refId: C
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: threshold
              expression: B
              conditions:
                - evaluator:
                    params:
                      - 1000
                    type: gt
                  type: query
              refId: C
        noDataState: OK
        execErrState: Error
        for: 5m
        annotations:
          description: 'Queue has {{ if $values.B }}{{ printf "%.0f" $values.B.Value }}{{ else }}N/A{{ end }} items (threshold: 1000)'
          summary: Upload or substrate queue is backing up
        labels:
          severity: critical

      - uid: monitoring-pipeline-down
        title: Monitoring Pipeline Down
        condition: A
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: PBFA97CFB590B2093
            model:
              expr: 'absent(up{job="otel-collector"})'
              refId: A
        noDataState: OK
        execErrState: Error
        for: 5m
        annotations:
          description: 'No metrics received from otel-collector for 5+ minutes'
          summary: Monitoring pipeline is down - cannot observe system health
        labels:
          severity: critical

      - uid: consecutive-upload-failures
        title: Consecutive Upload Failures
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: PBFA97CFB590B2093
            model:
              expr: 'increase(s3_errors_total{job="otel-collector",operation="put_object",error_type=~"http_5.*|internal_error|http_408"}[5m])'
              refId: A
          - refId: B
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: reduce
              expression: A
              reducer: last
              refId: B
          - refId: C
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: threshold
              expression: B
              conditions:
                - evaluator:
                    params:
                      - 3
                    type: gt
                  type: query
              refId: C
        noDataState: OK
        execErrState: Error
        for: 2m
        annotations:
          description: '{{ if $values.B }}{{ printf "%.0f" $values.B.Value }}{{ else }}N/A{{ end }} server errors during uploads in last 5 minutes (excludes auth failures)'
          summary: Multiple upload server errors detected - users impacted
        labels:
          severity: critical

  - orgId: 1
    name: hippius-s3-high-priority
    folder: Hippius S3 Alerts
    interval: 1m
    rules:
      - uid: upload-failures-detected
        title: Upload Failures Detected
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: PBFA97CFB590B2093
            model:
              expr: 'sum(increase(s3_errors_total{job="otel-collector",operation="put_object",error_type=~"http_5.*|internal_error"}[5m])) or vector(0)'
              refId: A
          - refId: B
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: reduce
              expression: A
              reducer: last
              refId: B
          - refId: C
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: threshold
              expression: B
              conditions:
                - evaluator:
                    params:
                      - 5
                    type: gt
                  type: query
              refId: C
        noDataState: OK
        execErrState: Error
        for: 5m
        annotations:
          summary: 'Uploads are failing - {{ if $values.B }}{{ printf "%.0f" $values.B.Value }}{{ else }}N/A{{ end }} errors in last 5 minutes'
          description: 'PUT operations returning 5xx errors. Check IPFS/storage backend.'
        labels:
          severity: critical

      - uid: download-failures-detected
        title: Download Failures Detected
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: PBFA97CFB590B2093
            model:
              expr: 'sum(increase(s3_errors_total{job="otel-collector",operation="get_object",error_type=~"http_5.*|internal_error"}[5m])) or vector(0)'
              refId: A
          - refId: B
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: reduce
              expression: A
              reducer: last
              refId: B
          - refId: C
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: threshold
              expression: B
              conditions:
                - evaluator:
                    params:
                      - 5
                    type: gt
                  type: query
              refId: C
        noDataState: OK
        execErrState: Error
        for: 5m
        annotations:
          summary: 'Downloads are failing - {{ if $values.B }}{{ printf "%.0f" $values.B.Value }}{{ else }}N/A{{ end }} errors in last 5 minutes'
          description: 'GET operations returning 5xx errors. Check IPFS/cache.'
        labels:
          severity: critical

      - uid: s3-system-down
        title: S3 System Down
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 600
              to: 0
            datasourceUid: PBFA97CFB590B2093
            model:
              expr: 'sum(increase(http_requests_total{job="otel-collector"}[10m])) or vector(0)'
              refId: A
          - refId: B
            relativeTimeRange:
              from: 600
              to: 0
            datasourceUid: __expr__
            model:
              type: reduce
              expression: A
              reducer: last
              refId: B
          - refId: C
            relativeTimeRange:
              from: 600
              to: 0
            datasourceUid: __expr__
            model:
              type: threshold
              expression: B
              conditions:
                - evaluator:
                    params:
                      - 1
                    type: lt
                  type: query
              refId: C
        noDataState: Alerting
        execErrState: Error
        for: 10m
        annotations:
          summary: 'S3 gateway not receiving traffic for 10+ minutes'
          description: 'No HTTP requests detected. System may be down or unreachable.'
        labels:
          severity: critical

      - uid: slow-response-time-during-activity
        title: Slow Response Time During Activity
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: PBFA97CFB590B2093
            model:
              expr: '((sum(increase(http_requests_total{job="otel-collector"}[5m])) or vector(0)) >= 5) and (histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{job="otel-collector"}[5m])))'
              refId: A
          - refId: B
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: reduce
              expression: A
              reducer: last
              refId: B
          - refId: C
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: threshold
              expression: B
              conditions:
                - evaluator:
                    params:
                      - 30
                    type: gt
                  type: query
              refId: C
        noDataState: OK
        execErrState: Error
        for: 5m
        annotations:
          description: 'P95 response time is {{ if $values.B }}{{ printf "%.2f" $values.B.Value }}{{ else }}N/A{{ end }}s during active traffic (threshold: 30s)'
          summary: API response times severely degraded during user activity
        labels:
          severity: high
