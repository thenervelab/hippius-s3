apiVersion: 1

groups:
  - orgId: 1
    name: hippius-s3-critical
    folder: Hippius S3 Alerts
    interval: 1m
    rules:
      - uid: redis-memory-exhaustion
        title: Redis Memory Exhaustion
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: PBFA97CFB590B2093
            model:
              expr: '(redis_memory_used_bytes / redis_memory_max_bytes) * 100'
              refId: A
          - refId: B
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: reduce
              expression: A
              reducer: last
              refId: B
          - refId: C
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: threshold
              expression: B
              conditions:
                - evaluator:
                    params:
                      - 90
                    type: gt
                  type: query
              refId: C
        noDataState: NoData
        execErrState: Error
        for: 3m
        annotations:
          description: 'Redis memory usage is {{ if $values.B }}{{ printf "%.2f" $values.B.Value }}{{ else }}N/A{{ end }}% (threshold: 90%)'
          summary: Redis memory usage critically high
        labels:
          severity: critical

      - uid: upload-queue-backup
        title: Upload Queue Backup
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: PBFA97CFB590B2093
            model:
              expr: 'hippius_queue_length{queue_name="upload_requests"}'
              refId: A
          - refId: B
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: reduce
              expression: A
              reducer: last
              refId: B
          - refId: C
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: threshold
              expression: B
              conditions:
                - evaluator:
                    params:
                      - 1000
                    type: gt
                  type: query
              refId: C
        noDataState: NoData
        execErrState: Error
        for: 5m
        annotations:
          description: 'Upload queue has {{ if $values.B }}{{ printf "%.0f" $values.B.Value }}{{ else }}N/A{{ end }} items (threshold: 1000)'
          summary: Upload processing is falling behind
        labels:
          severity: critical

      - uid: substrate-queue-backup
        title: Substrate Queue Backup
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: PBFA97CFB590B2093
            model:
              expr: 'hippius_queue_length{queue_name="substrate_requests"}'
              refId: A
          - refId: B
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: reduce
              expression: A
              reducer: last
              refId: B
          - refId: C
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: threshold
              expression: B
              conditions:
                - evaluator:
                    params:
                      - 500
                    type: gt
                  type: query
              refId: C
        noDataState: NoData
        execErrState: Error
        for: 5m
        annotations:
          description: 'Substrate queue has {{ if $values.B }}{{ printf "%.0f" $values.B.Value }}{{ else }}N/A{{ end }} items (threshold: 500)'
          summary: Blockchain publishing is falling behind
        labels:
          severity: critical

      - uid: high-error-rate
        title: High Error Rate
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: PBFA97CFB590B2093
            model:
              expr: '(sum(rate(http_requests_total{job="otel-collector"}[5m])) * 60 > 10) and ((sum(rate(s3_errors_total{job="otel-collector"}[5m])) or vector(0)) / (sum(rate(http_requests_total{job="otel-collector"}[5m])) + 0.0001) * 100)'
              refId: A
          - refId: B
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: reduce
              expression: A
              reducer: last
              refId: B
          - refId: C
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: threshold
              expression: B
              conditions:
                - evaluator:
                    params:
                      - 10
                    type: gt
                  type: query
              refId: C
        noDataState: OK
        execErrState: Error
        for: 5m
        annotations:
          description: 'Error rate is {{ if $values.B }}{{ printf "%.2f" $values.B.Value }}{{ else }}N/A{{ end }}% during active traffic (threshold: 10%)'
          summary: S3 API error rate exceeds 10% during traffic
        labels:
          severity: critical

      - uid: monitoring-pipeline-down
        title: Monitoring Pipeline Down
        condition: A
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: PBFA97CFB590B2093
            model:
              expr: 'absent(up{job="otel-collector"})'
              refId: A
        noDataState: Alerting
        execErrState: Error
        for: 5m
        annotations:
          description: 'No metrics received from otel-collector for 5+ minutes'
          summary: Monitoring pipeline is down - cannot observe system health
        labels:
          severity: critical

  - orgId: 1
    name: hippius-s3-high-priority
    folder: Hippius S3 Alerts
    interval: 1m
    rules:
      - uid: response-time-degradation
        title: Response Time Degradation
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: PBFA97CFB590B2093
            model:
              expr: '(sum(rate(http_requests_total{job="otel-collector"}[5m])) * 60 > 10) and (histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{job="otel-collector"}[5m])))'
              refId: A
          - refId: B
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: reduce
              expression: A
              reducer: last
              refId: B
          - refId: C
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: threshold
              expression: B
              conditions:
                - evaluator:
                    params:
                      - 15
                    type: gt
                  type: query
              refId: C
        noDataState: OK
        execErrState: Error
        for: 5m
        annotations:
          description: 'P95 response time is {{ if $values.B }}{{ printf "%.2f" $values.B.Value }}{{ else }}N/A{{ end }}s during active traffic (threshold: 15s)'
          summary: API response times are degraded
        labels:
          severity: high

      - uid: substrate-submission-failures
        title: Substrate Submission Failures
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: PBFA97CFB590B2093
            model:
              expr: '(sum(rate(substrate_requests_total{job="otel-collector"}[5m])) * 60 > 10) and ((sum(rate(substrate_requests_total{job="otel-collector",success="false"}[5m])) or vector(0)) / (sum(rate(substrate_requests_total{job="otel-collector"}[5m])) + 0.0001) * 100)'
              refId: A
          - refId: B
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: reduce
              expression: A
              reducer: last
              refId: B
          - refId: C
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: __expr__
            model:
              type: threshold
              expression: B
              conditions:
                - evaluator:
                    params:
                      - 10
                    type: gt
                  type: query
              refId: C
        noDataState: OK
        execErrState: Error
        for: 5m
        annotations:
          description: 'Substrate failure rate is {{ if $values.B }}{{ printf "%.2f" $values.B.Value }}{{ else }}N/A{{ end }}% during active traffic (threshold: 10%)'
          summary: Blockchain integration experiencing failures
        labels:
          severity: high
