name: Deploy to K8s Staging

on:
  push:
    branches: [k8s-staging]
  workflow_dispatch:

concurrency:
  group: k8s-staging-deployment
  cancel-in-progress: true

jobs:
  deploy:
    runs-on: ubuntu-latest
    environment: staging

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build and push Docker images
        run: |
          IMAGE_TAG=latest
          COMMIT_SHA=${{ github.sha }}

          echo "Building images with tag: $IMAGE_TAG"

          # Build base image
          docker buildx build \
            --platform linux/amd64 \
            --file Dockerfile.base \
            --tag ghcr.io/thenervelab/hippius-s3/base:$IMAGE_TAG \
            --tag ghcr.io/thenervelab/hippius-s3/base:$COMMIT_SHA \
            --cache-from type=registry,ref=ghcr.io/thenervelab/hippius-s3/base:latest \
            --cache-to type=inline \
            --push \
            .

          # Build API image
          docker buildx build \
            --platform linux/amd64 \
            --file Dockerfile \
            --build-arg BASE_IMAGE=ghcr.io/thenervelab/hippius-s3/base:$IMAGE_TAG \
            --tag ghcr.io/thenervelab/hippius-s3/api:$IMAGE_TAG \
            --tag ghcr.io/thenervelab/hippius-s3/api:$COMMIT_SHA \
            --cache-from type=registry,ref=ghcr.io/thenervelab/hippius-s3/base:latest \
            --cache-from type=registry,ref=ghcr.io/thenervelab/hippius-s3/api:latest \
            --cache-to type=inline \
            --push \
            .

          # Build Gateway image
          docker buildx build \
            --platform linux/amd64 \
            --file gateway/Dockerfile \
            --build-arg BASE_IMAGE=ghcr.io/thenervelab/hippius-s3/base:$IMAGE_TAG \
            --tag ghcr.io/thenervelab/hippius-s3/gateway:$IMAGE_TAG \
            --tag ghcr.io/thenervelab/hippius-s3/gateway:$COMMIT_SHA \
            --cache-from type=registry,ref=ghcr.io/thenervelab/hippius-s3/base:latest \
            --cache-from type=registry,ref=ghcr.io/thenervelab/hippius-s3/gateway:latest \
            --cache-to type=inline \
            --push \
            .

          # Build Workers image
          docker buildx build \
            --platform linux/amd64 \
            --file workers/Dockerfile \
            --build-arg BASE_IMAGE=ghcr.io/thenervelab/hippius-s3/base:$IMAGE_TAG \
            --tag ghcr.io/thenervelab/hippius-s3/workers:$IMAGE_TAG \
            --tag ghcr.io/thenervelab/hippius-s3/workers:$COMMIT_SHA \
            --cache-from type=registry,ref=ghcr.io/thenervelab/hippius-s3/base:latest \
            --cache-from type=registry,ref=ghcr.io/thenervelab/hippius-s3/workers:latest \
            --cache-to type=inline \
            --push \
            .

          echo "All images built and pushed successfully"

      - name: Set up kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'v1.28.0'

      - name: Configure kubectl
        run: |
          mkdir -p ~/.kube
          echo "${{ secrets.KUBE_CONFIG }}" | base64 -d > ~/.kube/config
          chmod 600 ~/.kube/config

          # Verify kubeconfig was written
          if [ ! -s ~/.kube/config ]; then
            echo "Error: kubeconfig file is empty"
            exit 1
          fi

          # Debug: show kubeconfig structure (without credentials)
          echo "Kubeconfig clusters:"
          kubectl config get-clusters

          echo "Kubeconfig contexts:"
          kubectl config get-contexts

          # Set current context if not set
          CONTEXT=$(kubectl config current-context 2>/dev/null || kubectl config get-contexts -o name | head -1)
          if [ -n "$CONTEXT" ]; then
            kubectl config use-context "$CONTEXT"
          fi

          kubectl version --client

      - name: Verify cluster connection
        run: |
          kubectl cluster-info
          kubectl get nodes

      - name: Create namespace
        run: |
          kubectl create namespace hippius-s3-staging --dry-run=client -o yaml | kubectl apply -f -
          kubectl label namespace hippius-s3-staging environment=staging --overwrite

      - name: Create postgres-superuser secret
        run: |
          kubectl create secret generic postgres-superuser \
            --from-literal=username=postgres \
            --from-literal=password='${{ secrets.DATABASE_PASSWORD }}' \
            --namespace=hippius-s3-staging \
            --dry-run=client -o yaml | kubectl apply -f -

      - name: Create postgres-backup-creds secret
        run: |
          kubectl create secret generic postgres-backup-creds \
            --from-literal=ACCESS_KEY_ID='${{ secrets.OVH_BACKUP_ACCESS_KEY_ID }}' \
            --from-literal=ACCESS_KEY_SECRET='${{ secrets.OVH_BACKUP_SECRET_ACCESS_KEY }}' \
            --namespace=hippius-s3-staging \
            --dry-run=client -o yaml | kubectl apply -f -

      - name: Create hippius-s3-secrets
        run: |
          # Construct DATABASE_URL from DATABASE_PASSWORD to ensure consistency
          DATABASE_URL="postgresql://postgres:${{ secrets.DATABASE_PASSWORD }}@postgres-rw:5432/hippius?sslmode=disable"
          echo "DATABASE_URL: postgresql://postgres:****@postgres-rw:5432/hippius?sslmode=disable"

          kubectl create secret generic hippius-s3-secrets \
            --from-literal=DATABASE_PASSWORD='${{ secrets.DATABASE_PASSWORD }}' \
            --from-literal=DATABASE_URL="${DATABASE_URL}" \
            --from-literal=HIPPIUS_KEYSTORE_DATABASE_URL="${DATABASE_URL}" \
            --from-literal=REDIS_URL='redis://redis:6379' \
            --from-literal=REDIS_ACCOUNTS_URL='redis://redis-accounts:6379' \
            --from-literal=REDIS_CHAIN_URL='redis://redis-chain:6379' \
            --from-literal=REDIS_QUEUES_URL='redis://redis-queues:6379' \
            --from-literal=REDIS_RATE_LIMITING_URL='redis://redis-rate-limiting:6379' \
            --from-literal=REDIS_ACL_URL='redis://redis-acl:6379' \
            --from-literal=HIPPIUS_SERVICE_KEY='${{ secrets.HIPPIUS_SERVICE_KEY }}' \
            --from-literal=HIPPIUS_AUTH_ENCRYPTION_KEY='${{ secrets.HIPPIUS_AUTH_ENCRYPTION_KEY }}' \
            --from-literal=HIPPIUS_IPFS_API_URLS='${{ secrets.HIPPIUS_IPFS_API_URLS }}' \
            --namespace=hippius-s3-staging \
            --dry-run=client -o yaml | kubectl apply -f -

          # Verify secret was created and show keys
          echo -e "\nSecret keys created:"
          kubectl get secret hippius-s3-secrets -n hippius-s3-staging -o jsonpath='{.data}' | jq -r 'keys[]'

      - name: Configure backup settings
        run: |
          sed -i "s|BACKUP_BUCKET_PLACEHOLDER|${{ secrets.OVH_BACKUP_BUCKET }}|g" k8s/staging/postgres-backup.yaml
          sed -i "s|BACKUP_ENDPOINT_PLACEHOLDER|${{ secrets.OVH_BACKUP_ENDPOINT_URL }}|g" k8s/staging/postgres-backup.yaml

          # Show what was configured (without secrets)
          echo "Backup configuration:"
          grep -A 5 "barmanObjectStore:" k8s/staging/postgres-backup.yaml || true

      - name: Delete old failed migration job
        run: |
          # Delete old migration job if it exists (allows fresh retry)
          kubectl delete job db-migrations -n hippius-s3-staging --ignore-not-found=true
          echo "Cleaned up old migration job"

      - name: Deploy with Kustomize
        run: |
          kubectl apply -k k8s/staging

      - name: Wait for PostgreSQL cluster
        run: |
          echo "Waiting for PostgreSQL cluster to be ready..."

          # Wait for cluster to be ready
          for i in {1..60}; do
            STATUS=$(kubectl get cluster postgres -n hippius-s3-staging -o jsonpath='{.status.phase}' 2>/dev/null || echo "not-found")
            echo "Attempt $i/60: Cluster status: $STATUS"

            if [ "$STATUS" = "Cluster in healthy state" ]; then
              echo "PostgreSQL cluster is ready!"
              break
            fi

            if [ $i -eq 60 ]; then
              echo "ERROR: PostgreSQL cluster not ready after 10 minutes"
              kubectl describe cluster postgres -n hippius-s3-staging
              exit 1
            fi

            sleep 10
          done

          # Verify postgres-rw service exists
          echo -e "\n=== Checking for postgres-rw service ==="
          for i in {1..30}; do
            if kubectl get svc postgres-rw -n hippius-s3-staging &>/dev/null; then
              echo "postgres-rw service found!"
              kubectl get svc postgres-rw -n hippius-s3-staging
              break
            fi
            echo "Waiting for postgres-rw service... ($i/30)"
            sleep 5
          done

          # Show cluster details
          echo -e "\n=== PostgreSQL Cluster Status ==="
          kubectl get cluster postgres -n hippius-s3-staging

          echo -e "\n=== PostgreSQL Pods ==="
          kubectl get pods -n hippius-s3-staging -l cnpg.io/cluster=postgres

          echo -e "\n=== PostgreSQL Services ==="
          kubectl get svc -n hippius-s3-staging | grep postgres

          echo -e "\n=== Testing Database Connectivity ==="
          # Test if we can connect to postgres-rw from within the cluster
          kubectl run test-db-connection --rm -i --restart=Never \
            --image=postgres:15 \
            --namespace=hippius-s3-staging \
            --env="PGPASSWORD=${{ secrets.DATABASE_PASSWORD }}" \
            --command -- psql -h postgres-rw -U postgres -d hippius -c "SELECT version();" 2>&1 || \
            echo "Failed to connect to database"

      - name: Check migration job
        run: |
          echo "Checking database migration job..."

          # Show job status
          kubectl get job db-migrations -n hippius-s3-staging -o yaml || true

          # Show pod status
          kubectl get pods -n hippius-s3-staging -l job-name=db-migrations || true

          # Get migration pod logs (try all pods, including failed ones)
          echo "=== Looking for migration pods ==="
          kubectl get pods -n hippius-s3-staging -l job-name=db-migrations --show-labels || true

          # Try to get logs from any pod (current or previous)
          for POD in $(kubectl get pods -n hippius-s3-staging -l job-name=db-migrations -o jsonpath='{.items[*].metadata.name}' 2>/dev/null); do
            echo -e "\n=== Pod: $POD ==="

            echo "Init container logs (wait-for-postgres):"
            kubectl logs -n hippius-s3-staging "$POD" -c wait-for-postgres --tail=100 2>/dev/null || \
              kubectl logs -n hippius-s3-staging "$POD" -c wait-for-postgres --previous --tail=100 2>/dev/null || \
              echo "No logs available"

            echo -e "\nMain container logs (migrations):"
            kubectl logs -n hippius-s3-staging "$POD" -c migrations --tail=100 2>/dev/null || \
              kubectl logs -n hippius-s3-staging "$POD" -c migrations --previous --tail=100 2>/dev/null || \
              echo "No logs available"

            echo -e "\nPod events:"
            kubectl describe pod "$POD" -n hippius-s3-staging | grep -A 20 "Events:" || true
          done

          # Check for events related to the job
          echo -e "\n=== Recent Events for Migration Job ==="
          kubectl get events -n hippius-s3-staging --sort-by='.lastTimestamp' | grep -i "db-migration" | tail -20 || true

          # Check PostgreSQL services
          echo -e "\n=== PostgreSQL Services ==="
          kubectl get svc -n hippius-s3-staging | grep postgres || true

          # Check PostgreSQL cluster status
          echo -e "\n=== PostgreSQL Cluster Status ==="
          kubectl get cluster postgres -n hippius-s3-staging -o yaml | grep -A 20 "status:" || true

          # Wait for job (allow failure for now)
          kubectl wait --for=condition=complete job/db-migrations \
            -n hippius-s3-staging \
            --timeout=300s || echo "Migration job did not complete in time"

      - name: Restart all deployments
        run: |
          echo "Restarting all deployments to pick up latest code..."
          kubectl rollout restart deployment/api -n hippius-s3-staging
          kubectl rollout restart deployment/gateway -n hippius-s3-staging
          kubectl rollout restart deployment/uploader -n hippius-s3-staging
          kubectl rollout restart deployment/downloader -n hippius-s3-staging
          kubectl rollout restart deployment/unpinner -n hippius-s3-staging
          kubectl rollout restart deployment/janitor -n hippius-s3-staging
          kubectl rollout restart deployment/account-cacher -n hippius-s3-staging
          echo "All deployments restarted"

      - name: Wait for deployments
        run: |
          echo "Waiting for API deployment..."
          kubectl rollout status deployment/api -n hippius-s3-staging --timeout=300s || echo "API deployment failed"

          echo "Waiting for Gateway deployment..."
          kubectl rollout status deployment/gateway -n hippius-s3-staging --timeout=300s || echo "Gateway deployment failed"

          echo "Waiting for worker deployments..."
          kubectl rollout status deployment/uploader -n hippius-s3-staging --timeout=300s || echo "Uploader deployment failed"
          kubectl rollout status deployment/downloader -n hippius-s3-staging --timeout=300s || echo "Downloader deployment failed"

      - name: Debug deployment failures
        if: always()
        run: |
          echo "=== Deployment Status ==="
          kubectl get deployments -n hippius-s3-staging

          echo -e "\n=== Pod Status ==="
          kubectl get pods -n hippius-s3-staging -o wide

          echo -e "\n=== Failed/Crashing Pods ==="
          for POD in $(kubectl get pods -n hippius-s3-staging --field-selector=status.phase!=Running,status.phase!=Succeeded -o jsonpath='{.items[*].metadata.name}' 2>/dev/null); do
            echo -e "\n--- Pod: $POD ---"
            kubectl describe pod "$POD" -n hippius-s3-staging | tail -30

            echo -e "\nLogs:"
            kubectl logs "$POD" -n hippius-s3-staging --tail=50 --all-containers=true 2>&1 || \
              kubectl logs "$POD" -n hippius-s3-staging --previous --tail=50 --all-containers=true 2>&1 || \
              echo "No logs available"
          done

          echo -e "\n=== API Pod Logs (if running) ==="
          kubectl logs -n hippius-s3-staging -l app=api --tail=50 --all-containers=true 2>&1 || echo "No API pods found"

          echo -e "\n=== Gateway Pod Logs (if running) ==="
          kubectl logs -n hippius-s3-staging -l app=gateway --tail=50 --all-containers=true 2>&1 || echo "No Gateway pods found"

          echo -e "\n=== Recent Events ==="
          kubectl get events -n hippius-s3-staging --sort-by='.lastTimestamp' | tail -30

      - name: Verify deployment
        run: |
          echo "=== Cluster Status ==="
          kubectl get cluster -n hippius-s3-staging

          echo -e "\n=== Services ==="
          kubectl get svc -n hippius-s3-staging

          echo -e "\n=== PVCs ==="
          kubectl get pvc -n hippius-s3-staging

          echo -e "\n=== Pods ==="
          kubectl get pods -n hippius-s3-staging

          echo -e "\n=== Scheduled Backups ==="
          kubectl get scheduledbackups -n hippius-s3-staging || true

      - name: Check pod health
        run: |
          echo "Checking for unhealthy pods..."
          kubectl get pods -n hippius-s3-staging -o json | \
            jq -r '.items[] | select(.status.phase != "Running" and .status.phase != "Succeeded") | .metadata.name' || true

      - name: Notify Discord on success
        if: success()
        run: |
          curl -H "Content-Type: application/json" \
            -X POST \
            -d "{\"content\":\"✅ K8s Staging deployment successful\"}" \
            ${{ secrets.DISCORD_WEBHOOK_URL }}

      - name: Notify Discord on failure
        if: failure()
        run: |
          curl -H "Content-Type: application/json" \
            -X POST \
            -d "{\"content\":\"❌ K8s Staging deployment failed - check GitHub Actions logs\"}" \
            ${{ secrets.DISCORD_WEBHOOK_URL }}
