name: Deploy to K8s Staging

on:
  push:
    branches: [k8s-staging]
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest
    environment: staging

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'v1.28.0'

      - name: Configure kubectl
        run: |
          mkdir -p ~/.kube
          echo "${{ secrets.KUBE_CONFIG }}" | base64 -d > ~/.kube/config
          chmod 600 ~/.kube/config

          # Verify kubeconfig was written
          if [ ! -s ~/.kube/config ]; then
            echo "Error: kubeconfig file is empty"
            exit 1
          fi

          # Debug: show kubeconfig structure (without credentials)
          echo "Kubeconfig clusters:"
          kubectl config get-clusters

          echo "Kubeconfig contexts:"
          kubectl config get-contexts

          # Set current context if not set
          CONTEXT=$(kubectl config current-context 2>/dev/null || kubectl config get-contexts -o name | head -1)
          if [ -n "$CONTEXT" ]; then
            kubectl config use-context "$CONTEXT"
          fi

          kubectl version --client

      - name: Verify cluster connection
        run: |
          kubectl cluster-info
          kubectl get nodes

      - name: Create namespace
        run: |
          kubectl create namespace hippius-s3-staging --dry-run=client -o yaml | kubectl apply -f -
          kubectl label namespace hippius-s3-staging environment=staging --overwrite

      - name: Create postgres-superuser secret
        run: |
          kubectl create secret generic postgres-superuser \
            --from-literal=username=postgres \
            --from-literal=password='${{ secrets.DATABASE_PASSWORD }}' \
            --namespace=hippius-s3-staging \
            --dry-run=client -o yaml | kubectl apply -f -

      - name: Create postgres-backup-creds secret
        run: |
          kubectl create secret generic postgres-backup-creds \
            --from-literal=ACCESS_KEY_ID='${{ secrets.OVH_BACKUP_ACCESS_KEY_ID }}' \
            --from-literal=ACCESS_KEY_SECRET='${{ secrets.OVH_BACKUP_SECRET_ACCESS_KEY }}' \
            --namespace=hippius-s3-staging \
            --dry-run=client -o yaml | kubectl apply -f -

      - name: Create hippius-s3-secrets
        run: |
          kubectl create secret generic hippius-s3-secrets \
            --from-literal=DATABASE_PASSWORD='${{ secrets.DATABASE_PASSWORD }}' \
            --from-literal=DATABASE_URL='${{ secrets.STAGING_DATABASE_URL }}' \
            --from-literal=HIPPIUS_KEYSTORE_DATABASE_URL='${{ secrets.STAGING_DATABASE_URL }}' \
            --from-literal=REDIS_URL='redis://redis:6379' \
            --from-literal=REDIS_ACCOUNTS_URL='redis://redis-accounts:6379' \
            --from-literal=REDIS_CHAIN_URL='redis://redis-chain:6379' \
            --from-literal=REDIS_QUEUES_URL='redis://redis-queues:6379' \
            --from-literal=REDIS_RATE_LIMITING_URL='redis://redis-rate-limiting:6379' \
            --from-literal=REDIS_ACL_URL='redis://redis-acl:6379' \
            --from-literal=HIPPIUS_SERVICE_KEY='${{ secrets.HIPPIUS_SERVICE_KEY }}' \
            --from-literal=HIPPIUS_AUTH_ENCRYPTION_KEY='${{ secrets.HIPPIUS_AUTH_ENCRYPTION_KEY }}' \
            --from-literal=HIPPIUS_IPFS_API_URLS='http://ipfs:5001' \
            --namespace=hippius-s3-staging \
            --dry-run=client -o yaml | kubectl apply -f -

      - name: Configure backup settings
        run: |
          sed -i "s|BACKUP_BUCKET_PLACEHOLDER|${{ secrets.OVH_BACKUP_BUCKET }}|g" k8s/staging/postgres-backup.yaml
          sed -i "s|BACKUP_ENDPOINT_PLACEHOLDER|${{ secrets.OVH_BACKUP_ENDPOINT_URL }}|g" k8s/staging/postgres-backup.yaml

          # Show what was configured (without secrets)
          echo "Backup configuration:"
          grep -A 5 "barmanObjectStore:" k8s/staging/postgres-backup.yaml || true

      - name: Delete old failed migration job
        run: |
          # Delete old migration job if it exists (allows fresh retry)
          kubectl delete job db-migrations -n hippius-s3-staging --ignore-not-found=true
          echo "Cleaned up old migration job"

      - name: Deploy with Kustomize
        run: |
          kubectl apply -k k8s/staging

      - name: Wait for PostgreSQL cluster
        run: |
          echo "Waiting for PostgreSQL cluster to be ready..."

          # Wait for cluster to be ready
          for i in {1..60}; do
            STATUS=$(kubectl get cluster postgres -n hippius-s3-staging -o jsonpath='{.status.phase}' 2>/dev/null || echo "not-found")
            echo "Attempt $i/60: Cluster status: $STATUS"

            if [ "$STATUS" = "Cluster in healthy state" ]; then
              echo "PostgreSQL cluster is ready!"
              break
            fi

            if [ $i -eq 60 ]; then
              echo "ERROR: PostgreSQL cluster not ready after 10 minutes"
              kubectl describe cluster postgres -n hippius-s3-staging
              exit 1
            fi

            sleep 10
          done

          # Verify postgres-rw service exists
          echo -e "\n=== Checking for postgres-rw service ==="
          for i in {1..30}; do
            if kubectl get svc postgres-rw -n hippius-s3-staging &>/dev/null; then
              echo "postgres-rw service found!"
              kubectl get svc postgres-rw -n hippius-s3-staging
              break
            fi
            echo "Waiting for postgres-rw service... ($i/30)"
            sleep 5
          done

          # Show cluster details
          echo -e "\n=== PostgreSQL Cluster Status ==="
          kubectl get cluster postgres -n hippius-s3-staging

          echo -e "\n=== PostgreSQL Pods ==="
          kubectl get pods -n hippius-s3-staging -l cnpg.io/cluster=postgres

          echo -e "\n=== PostgreSQL Services ==="
          kubectl get svc -n hippius-s3-staging | grep postgres

      - name: Check migration job
        run: |
          echo "Checking database migration job..."

          # Show job status
          kubectl get job db-migrations -n hippius-s3-staging -o yaml || true

          # Show pod status
          kubectl get pods -n hippius-s3-staging -l job-name=db-migrations || true

          # Get migration pod logs (try all pods, including failed ones)
          echo "=== Looking for migration pods ==="
          kubectl get pods -n hippius-s3-staging -l job-name=db-migrations --show-labels || true

          # Try to get logs from any pod (current or previous)
          for POD in $(kubectl get pods -n hippius-s3-staging -l job-name=db-migrations -o jsonpath='{.items[*].metadata.name}' 2>/dev/null); do
            echo -e "\n=== Pod: $POD ==="

            echo "Init container logs (wait-for-postgres):"
            kubectl logs -n hippius-s3-staging "$POD" -c wait-for-postgres --tail=100 2>/dev/null || \
              kubectl logs -n hippius-s3-staging "$POD" -c wait-for-postgres --previous --tail=100 2>/dev/null || \
              echo "No logs available"

            echo -e "\nMain container logs (migrations):"
            kubectl logs -n hippius-s3-staging "$POD" -c migrations --tail=100 2>/dev/null || \
              kubectl logs -n hippius-s3-staging "$POD" -c migrations --previous --tail=100 2>/dev/null || \
              echo "No logs available"

            echo -e "\nPod events:"
            kubectl describe pod "$POD" -n hippius-s3-staging | grep -A 20 "Events:" || true
          done

          # Check for events related to the job
          echo -e "\n=== Recent Events for Migration Job ==="
          kubectl get events -n hippius-s3-staging --sort-by='.lastTimestamp' | grep -i "db-migration" | tail -20 || true

          # Check PostgreSQL services
          echo -e "\n=== PostgreSQL Services ==="
          kubectl get svc -n hippius-s3-staging | grep postgres || true

          # Check PostgreSQL cluster status
          echo -e "\n=== PostgreSQL Cluster Status ==="
          kubectl get cluster postgres -n hippius-s3-staging -o yaml | grep -A 20 "status:" || true

          # Wait for job (allow failure for now)
          kubectl wait --for=condition=complete job/db-migrations \
            -n hippius-s3-staging \
            --timeout=300s || echo "Migration job did not complete in time"

      - name: Wait for deployments
        run: |
          echo "Waiting for API deployment..."
          kubectl rollout status deployment/api -n hippius-s3-staging --timeout=300s || true

          echo "Waiting for Gateway deployment..."
          kubectl rollout status deployment/gateway -n hippius-s3-staging --timeout=300s || true

          echo "Waiting for worker deployments..."
          kubectl rollout status deployment/uploader -n hippius-s3-staging --timeout=300s || true
          kubectl rollout status deployment/downloader -n hippius-s3-staging --timeout=300s || true

      - name: Verify deployment
        run: |
          echo "=== Cluster Status ==="
          kubectl get cluster -n hippius-s3-staging

          echo -e "\n=== Services ==="
          kubectl get svc -n hippius-s3-staging

          echo -e "\n=== PVCs ==="
          kubectl get pvc -n hippius-s3-staging

          echo -e "\n=== Pods ==="
          kubectl get pods -n hippius-s3-staging

          echo -e "\n=== Scheduled Backups ==="
          kubectl get scheduledbackups -n hippius-s3-staging || true

      - name: Check pod health
        run: |
          echo "Checking for unhealthy pods..."
          kubectl get pods -n hippius-s3-staging -o json | \
            jq -r '.items[] | select(.status.phase != "Running" and .status.phase != "Succeeded") | .metadata.name' || true

      - name: Notify Discord on success
        if: success()
        run: |
          curl -H "Content-Type: application/json" \
            -X POST \
            -d "{\"content\":\"✅ K8s Staging deployment successful\"}" \
            ${{ secrets.DISCORD_WEBHOOK_URL }}

      - name: Notify Discord on failure
        if: failure()
        run: |
          curl -H "Content-Type: application/json" \
            -X POST \
            -d "{\"content\":\"❌ K8s Staging deployment failed - check GitHub Actions logs\"}" \
            ${{ secrets.DISCORD_WEBHOOK_URL }}
